{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipython'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45dce7411d31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mipython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipython'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ipython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# step1 Data preprocessing\n",
    "#load dataset\n",
    "boston=load_boston() \n",
    "#Description of the dataset\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the data into pandas data frames\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "features = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(boston.target,columns=['target'])\n",
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(target['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(target['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate features and target into single DataFrame\n",
    "#axis = 1 makes it concatenate column wise\n",
    "df = pd.concat([features,target],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use round(decimals=2) to set the precision to 2 decimal places\n",
    "df.describe().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlation between every columns of data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mp\n",
    "boston=load_boston()\n",
    "features = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "target = pd.DataFrame(boston.target,columns=['target'])\n",
    "df = pd.concat([features,target],axis=1)\n",
    "corr = df.corr('pearson')\n",
    "\n",
    "#take absolute  value of correlation\n",
    "corrs = [abs(corr[attr]['target']) for attr in list(features)]\n",
    "\n",
    "#make a list of pairs[(corr,features)]\n",
    "l = list(zip(corrs,list(features)))\n",
    "\n",
    "#sort the list of pairs in reverse/decending order\n",
    "#with the correlation value as the key for storing\n",
    "l.sort(key = lambda x : x[0], reverse = True)\n",
    "\n",
    "#'unzip' pairs to two lists\n",
    "#zip(*l) takes a list that looks like [[a,b,c], [d,e,f], [g,h,i]]\n",
    "#and returns [[a,d,g], [b,e,h], [c,f,i]]\n",
    "corrs, labels = list(zip((*l)))\n",
    "\n",
    "#plot correlation with respect to the target variable as a bar graph\n",
    "index = np.arange(len(labels))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(index, corrs, width=0.5)\n",
    "plt.xlabel('attributes')\n",
    "plt.ylabel('correlation with the target values')\n",
    "plt.xticks(index, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['LSTAT'].values\n",
    "y=df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before normalization\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler()\n",
    "x=x_scaler.fit_transform(x.reshape(-1, 1))\n",
    "x=x[:, -1]\n",
    "y_scaler = MinMaxScaler()\n",
    "y=y_scaler.fit_transform(y.reshape(-1, 1))\n",
    "y=y[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after normalization\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(m, x, c, t):\n",
    "    \n",
    "    n = x.size\n",
    "    e = sum(((m*x+c) - t)** 2)\n",
    "    \n",
    "    return e * 1/(2 * n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.2 indicates the 20% of data is randomly sampled  as test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "boston=load_boston()\n",
    "x = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,columns=['target'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(m, x, c, t, learning_rate):\n",
    "    grad_m = sum(2*((m*x+c)-t)*x)\n",
    "    grad_c = sum(2*((m*x+c)-t))\n",
    "    m = m-grad_m * learning_rate\n",
    "    c = c-grad_c * learning_rate\n",
    "    return m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(init_m, init_c, x, t,  learning_rate, iterations, error_threshold):\n",
    "    m = init_m\n",
    "    c = init_c\n",
    "    error_values = list()\n",
    "    mc_values = list()\n",
    "    for i in range(iterations):\n",
    "        e = error(m, x, c, t)\n",
    "        if e < error_threshold:\n",
    "            print('error less than threshold, stopping gradient descent')\n",
    "            break\n",
    "        error_values.append(e)\n",
    "        m, c = update(m, x, c, t, learning_rate)\n",
    "        mc_values.append((m, c))\n",
    "    return m, c, error_values, mc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def error(m, x, c, t):\n",
    "    \n",
    "    init_m = 0.9\n",
    "    init_c = 0\n",
    "    learning_rate = 0.001\n",
    "    iterations = 250\n",
    "    error_threshold = 0.001\n",
    "\n",
    "    m, c, error_values, mc_values = gradient_descent(init_m, init_c, xtrain, ytrain,  learning_rate, iterations, error_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the number of iterations increases , changes in the line are less noticible.\n",
    "#inorder to reduce the processing time for the animation ,it is advisable to choose smaller value\n",
    "mc_values = list()\n",
    "mc_values_anim = mc_values[0:250:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "#from . import ipython\n",
    "#import ipython as ip\n",
    "from ipython.display import HTML\n",
    "fig, ax = plt.subplots()\n",
    "ln, = plt.plot([], [], 'ro-', animated=True)\n",
    "\n",
    "def init():\n",
    "    plt.scatter(xtest, ytest, color='g')\n",
    "    ax.set_xlim(0, 1.0)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    return ln,\n",
    "def update_frame(frame):\n",
    "    m , c = mc_values_anim[frame]\n",
    "    x1, y1 = -0.5, m* -.5 + c\n",
    "    x2, y2 = 1.5, m* 1.5 + c\n",
    "    ln.set_data([x1,x2], [y1, y2])\n",
    "    return ln,\n",
    "\n",
    "anim = FuncAnimation(fig, update_frame, frames = range(len(mc_values_anim)),\n",
    "                                init_func=init, blit=True)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " python3 -m pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.size=y.size\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "boston=load_boston()\n",
    "x = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,columns=['target'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "plt.scatter(xtrain, ytrain, color='b' )\n",
    "plt.plot(xtrain, (m*xtrain+c), color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def gradient_descent(init_m, init_c, x, t,  learning_rate, iterations, error_threshold):\n",
    "    m = init_m\n",
    "    c = init_c\n",
    "    error_values = list()\n",
    "    mc_values = list()\n",
    "    for i in range(iterations):\n",
    "        e = error(m, x, c, t)\n",
    "        if e < error_threshold:\n",
    "            print('error less than threshold, stopping gradient descent')\n",
    "            break\n",
    "        error_values.append(e)\n",
    "        m, c = update(m, x, c, t, learning_rate)\n",
    "        mc_values.append((m, c))\n",
    "    return m, c, error_values, mc_values\n",
    "error_values = list()\n",
    "plt.plot(np.arange(len(error_values)), error_values)\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the predictions on the test set as a vectorised operatrions\n",
    "predicted = (m * xtest) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute MSE  for the predicted values on the testng set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "boston=load_boston()\n",
    "x = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target,columns=['target'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predicted = (m * xtest) + c\n",
    "mean_squared_error(ytest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put xtest,ytest,predicted values into a single data frame so that we \n",
    "#can show the predicted values alongside the testing values\n",
    "predicted = (m * xtest) + c\n",
    "p=pd.DataFrame(list(zip(xtest, ytest, predicted)),coloumns=['x', 'target_y', 'predicted_y'])\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xtest, ytest, color='b')\n",
    "plt.plot(xtest, predicted, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to change the shape that id required by the scaler\n",
    "predicted = (m * xtest) + c\n",
    "predicted=np.array(predicted).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to change the shape that is required by the scaler\n",
    "predicted = (m * xtest) + c\n",
    "predicted=predicted.reshape(-1,1)\n",
    "xtest=xtest.reshape(-1,1)\n",
    "ytest=ytest.reshape(-1,1)\n",
    "\n",
    "xtest_scaled=x_scaler.inverse_transform(xtest)\n",
    "ytest_scaled=y_scaler.inverse_transform(ytest)\n",
    "predicted_scaled=y_scaler.inverse_transform(predicted)\n",
    "\n",
    "#this is to remove the extra dimensions\n",
    "xtest_scaled=xtest_scaled[:, -1]\n",
    "ytest_scaled=ytest_scaled[:, -1]\n",
    "predicted_scaled=predicted_scaled[:, -1]\n",
    "\n",
    "p=pd.DataFrame(list(zip(xtest_scaled, ytest_scaled, predicted_scaled)),columns=['x', 'target_y', 'predicted_y'])\n",
    "p=p.round(decimals=2)\n",
    "p.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
